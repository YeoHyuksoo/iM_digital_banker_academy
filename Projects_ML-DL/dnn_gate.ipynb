{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84f71b2a-62a1-48cf-8da2-f693aa4e0862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db1e814-838a-40fe-a57f-9e079a30129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "447cdb0a-4e88-4671-a792-7758dbd57231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f,x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "\n",
    "        x[idx] = float(tmp_val) - delta_x\n",
    "        fx2 = f(x)\n",
    "\n",
    "        grad[idx] = (fx1 - fx2) / (2 * delta_x)\n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c8eb9a9-dfd5-4d5d-8754-3630c2ddf7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "    def __init__(self, gate_name, xdata, tdata):\n",
    "        self.name = gate_name\n",
    "        self.xdata = xdata.reshape(4, 2)\n",
    "        self.tdata = tdata.reshape(4, 1)\n",
    "        self.W = np.random.rand(self.xdata.shape[1], 1)\n",
    "        self.b = np.random.rand(1)\n",
    "        self.learning_rate = 1e-2\n",
    "\n",
    "    def loss_func(self):\n",
    "        delta = 1e-7\n",
    "        z = np.dot(self.xdata, self.W) + self.b\n",
    "        y = sigmoid(z)\n",
    "        return -np.sum(self.tdata * np.log(y + delta) + (1 - self.tdata) * np.log((1 - y) + delta))\n",
    "\n",
    "    def train(self):\n",
    "        f = lambda x : self.loss_func()\n",
    "        print(\"Initial loss value = \", self.loss_func())\n",
    "        for step in range(8001):\n",
    "            self.W -= self.learning_rate * numerical_derivative(f, self.W)\n",
    "            self.b -= self.learning_rate * numerical_derivative(f, self.b)\n",
    "            if (step % 1000 == 0):\n",
    "                print(\"step = \", step, \"loss value = \", self.loss_func())\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        z = np.dot(test_data, self.W) + self.b\n",
    "        y = sigmoid(z)\n",
    "        if y >= 0.5:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "            \n",
    "        return y, result\n",
    "\n",
    "    def accuracy(self, test_xdata, test_tdata):\n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        for index in range(len(xdata)):\n",
    "            (real_val, logical_val) = self.predict(test_xdata[index])\n",
    "            if logical_val == test_tdata[index]:\n",
    "                matched_list.append(index)\n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "        accuracy_val = len(matched_list) / len(test_xdata)\n",
    "        return accuracy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c696d433-4751-4d3c-b6ba-fa5926fc6193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss value =  4.41254555431711\n",
      "step =  0 loss value =  4.356985100078407\n",
      "step =  1000 loss value =  1.004977366665566\n",
      "step =  2000 loss value =  0.6594317348159655\n",
      "step =  3000 loss value =  0.4909493435450939\n",
      "step =  4000 loss value =  0.3899769211916553\n",
      "step =  5000 loss value =  0.3227014564797928\n",
      "step =  6000 loss value =  0.2747543244865454\n",
      "step =  7000 loss value =  0.2389187314793496\n",
      "step =  8000 loss value =  0.21116309086000157\n"
     ]
    }
   ],
   "source": [
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "tdata = np.array([0, 0, 0, 1])\n",
    "AND_obj = LogicGate(\"AND_GATE\", xdata, tdata)\n",
    "AND_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eb7dc1c-b506-4ef5-8391-db97c4c88142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]  =  0\n",
      "[0 0]  =  [0.0003694]\n",
      "[0 1]  =  0\n",
      "[0 1]  =  [0.05973536]\n",
      "[1 0]  =  0\n",
      "[1 0]  =  [0.05973523]\n",
      "[1 1]  =  1\n",
      "[1 1]  =  [0.91612143]\n",
      "--------------------------\n",
      "Accuracy =>  1.0\n"
     ]
    }
   ],
   "source": [
    "test_xdata = np.array([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "for input_data in test_xdata:\n",
    "    (sigmoid_val, logical_val) = AND_obj.predict(input_data)\n",
    "    print(input_data, \" = \", logical_val)\n",
    "    print(input_data, \" = \", sigmoid_val)\n",
    "print('--------------------------')\n",
    "test_tdata = np.array([0, 0, 0, 1])\n",
    "accuracy_ret = AND_obj.accuracy(test_xdata, test_tdata)\n",
    "print('Accuracy => ', accuracy_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd41252a-15fb-4d99-9cdc-6cb141797925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss value =  1.8048833223888323\n",
      "step =  0 loss value =  1.7999007494167807\n",
      "step =  1000 loss value =  0.6941247653247334\n",
      "step =  2000 loss value =  0.4216546040798512\n",
      "step =  3000 loss value =  0.29850824759473965\n",
      "step =  4000 loss value =  0.22947578960529727\n",
      "step =  5000 loss value =  0.18570650299059346\n",
      "step =  6000 loss value =  0.15563229869518608\n",
      "step =  7000 loss value =  0.13376434093479406\n",
      "step =  8000 loss value =  0.11718135668817034\n"
     ]
    }
   ],
   "source": [
    "xdata = np.array([ [0,0],[0,1],[1,0],[1,1]])\n",
    "tdata = np.array([0,1,1,1])\n",
    "OR_obj = LogicGate(\"OR GATE\",xdata,tdata)\n",
    "OR_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "849a710e-b013-4c74-9916-13ad8b4f8214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]  =  0\n",
      "[0 0]  =  [0.06369498]\n",
      "[0 1]  =  1\n",
      "[0 1]  =  [0.97472453]\n",
      "[1 0]  =  1\n",
      "[1 0]  =  [0.97460653]\n",
      "[1 1]  =  1\n",
      "[1 1]  =  [0.99995404]\n",
      "--------------------------\n",
      "Accuracy =>  1.0\n"
     ]
    }
   ],
   "source": [
    "test_xdata = np.array([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "for input_data in test_xdata:\n",
    "    (sigmoid_val, logical_val) = OR_obj.predict(input_data)\n",
    "    print(input_data, \" = \", logical_val)\n",
    "    print(input_data, \" = \", sigmoid_val)\n",
    "print('--------------------------')\n",
    "test_tdata = np.array([0, 1, 1, 1])\n",
    "accuracy_ret = OR_obj.accuracy(test_xdata, test_tdata)\n",
    "print('Accuracy => ', accuracy_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6f01adf-0e31-4065-91fa-1b17f8b56f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss value =  2.9849239880637137\n",
      "step =  0 loss value =  2.97935291701313\n",
      "step =  1000 loss value =  1.085858235209243\n",
      "step =  2000 loss value =  0.6922160842530609\n",
      "step =  3000 loss value =  0.5090744600794093\n",
      "step =  4000 loss value =  0.4014947450780016\n",
      "step =  5000 loss value =  0.33065148945752854\n",
      "step =  6000 loss value =  0.2805587464439807\n",
      "step =  7000 loss value =  0.2433344500321421\n",
      "step =  8000 loss value =  0.21463002209892643\n"
     ]
    }
   ],
   "source": [
    "xdata = np.array([ [0,0],[0,1],[1,0],[1,1]])\n",
    "tdata = np.array([1,1,1,0])\n",
    "NAND_obj = LogicGate(\"NAND GATE\",xdata,tdata)\n",
    "NAND_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c513152-176b-4c26-b554-8b381fbde64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]  =  1\n",
      "[0 0]  =  [0.99961153]\n",
      "[0 1]  =  1\n",
      "[0 1]  =  [0.93932504]\n",
      "[1 0]  =  1\n",
      "[1 0]  =  [0.93932563]\n",
      "[1 1]  =  0\n",
      "[1 1]  =  [0.08520485]\n",
      "--------------------------\n",
      "Accuracy =>  1.0\n"
     ]
    }
   ],
   "source": [
    "test_xdata = np.array([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "for input_data in test_xdata:\n",
    "    (sigmoid_val, logical_val) = NAND_obj.predict(input_data)\n",
    "    print(input_data, \" = \", logical_val)\n",
    "    print(input_data, \" = \", sigmoid_val)\n",
    "print('--------------------------')\n",
    "test_tdata = np.array([1, 1, 1, 0])\n",
    "accuracy_ret = NAND_obj.accuracy(test_xdata, test_tdata)\n",
    "print('Accuracy => ', accuracy_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bbef513-2a95-4e2b-b688-0539d4dd9a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss value =  3.5353069924753444\n",
      "step =  0 loss value =  3.5163811109614613\n",
      "step =  1000 loss value =  2.7727801605248006\n",
      "step =  2000 loss value =  2.7725909310327803\n",
      "step =  3000 loss value =  2.772588016005879\n",
      "step =  4000 loss value =  2.772587926016016\n",
      "step =  5000 loss value =  2.772587922399783\n",
      "step =  6000 loss value =  2.7725879222466903\n",
      "step =  7000 loss value =  2.7725879222401533\n",
      "step =  8000 loss value =  2.7725879222398744\n"
     ]
    }
   ],
   "source": [
    "xdata = np.array([ [0,0],[0,1],[1,0],[1,1]])\n",
    "tdata = np.array([0,1,1,0])\n",
    "XOR_obj = LogicGate(\"XOR GATE\",xdata,tdata)\n",
    "XOR_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bdc14e4-55d1-4156-8d71-a59706f5d787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]  =  1\n",
      "[0 0]  =  [0.50000006]\n",
      "[0 1]  =  1\n",
      "[0 1]  =  [0.50000001]\n",
      "[1 0]  =  1\n",
      "[1 0]  =  [0.50000001]\n",
      "[1 1]  =  0\n",
      "[1 1]  =  [0.49999996]\n",
      "--------------------------\n",
      "Accuracy =>  0.75\n"
     ]
    }
   ],
   "source": [
    "test_xdata = np.array([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "for input_data in test_xdata:\n",
    "    (sigmoid_val, logical_val) = XOR_obj.predict(input_data)\n",
    "    print(input_data, \" = \", logical_val)\n",
    "    print(input_data, \" = \", sigmoid_val)\n",
    "print('--------------------------')\n",
    "test_tdata = np.array([0, 1, 1, 0])\n",
    "accuracy_ret = XOR_obj.accuracy(test_xdata, test_tdata)\n",
    "print('Accuracy => ', accuracy_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f80a8b5-085f-4642-826d-9223e19e694e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]  =  0\n",
      "[0 1]  =  1\n",
      "[1 0]  =  1\n",
      "[1 1]  =  0\n"
     ]
    }
   ],
   "source": [
    "input_data = np.array([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "\n",
    "s1 = []\n",
    "s2 = []\n",
    "new_input_data = []\n",
    "final_output = []\n",
    "\n",
    "for index in range(len(input_data)):\n",
    "    s1 = NAND_obj.predict(input_data[index])\n",
    "    s2 = OR_obj.predict(input_data[index])\n",
    "    new_input_data.append(s1[-1])\n",
    "    new_input_data.append(s2[-1])\n",
    "    (sigmoid_val, logical_val) = AND_obj.predict(np.array(new_input_data))\n",
    "    final_output.append(logical_val)\n",
    "    new_input_data = []\n",
    "\n",
    "for index in range(len(input_data)):\n",
    "    print(input_data[index], \" = \", final_output[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f82e351-44e7-4fed-b976-09a22b1429b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f,x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "\n",
    "        x[idx] = float(tmp_val) - delta_x\n",
    "        fx2 = f(x)\n",
    "\n",
    "        grad[idx] = (fx1 - fx2) / (2 * delta_x)\n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ff7a602-f3e8-4a9d-b329-67a5b0f2abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "    def __init__(self, gate_name, xdata, tdata):\n",
    "        self.name = gate_name\n",
    "        self.xdata = xdata.reshape(4, 2)\n",
    "        self.tdata = tdata.reshape(4, 1)\n",
    "        \n",
    "        self.W2 = np.random.rand(2, 5)\n",
    "        self.W3 = np.random.rand(5, 2)\n",
    "        self.W4 = np.random.rand(2, 1)\n",
    "\n",
    "        self.b2 = np.random.rand(5)\n",
    "        self.b3 = np.random.rand(2)\n",
    "        self.b4 = np.random.rand(1)\n",
    "        \n",
    "        # self.learning_rate = 10\n",
    "        self.learning_rate = 0.05\n",
    "\n",
    "    def feed_forward(self):\n",
    "        delta = 1e-7\n",
    "        z2 = np.dot(self.xdata, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        a3 = sigmoid(z3)\n",
    "        z4 = np.dot(a3, self.W4) + self.b4\n",
    "        y = a4 = sigmoid(z4)\n",
    "        return -np.sum(self.tdata * np.log(y + delta) + (1 - self.tdata) * np.log((1 - y) + delta))\n",
    "\n",
    "    def feed_forward_print(self):\n",
    "        delta = 1e-7\n",
    "        z2 = np.dot(self.xdata, self.W2) + self.b2\n",
    "        print(\"z2 => \", z2)\n",
    "        a2 = sigmoid(z2)\n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        print(\"z3 => \", z3)\n",
    "        a3 = sigmoid(z3)\n",
    "        z4 = np.dot(a3, self.W4) + self.b4\n",
    "        print(\"z4 => \", z4)\n",
    "        y = a4 = sigmoid(z4)\n",
    "        return -np.sum(self.tdata * np.log(y + delta) + (1 - self.tdata) * np.log((1 - y) + delta))\n",
    "\n",
    "    def train(self):\n",
    "        f = lambda x : self.feed_forward()\n",
    "        print(\"Initial loss value = \", self.feed_forward())\n",
    "        \n",
    "        for step in range(7001):\n",
    "            self.W2 -= self.learning_rate * numerical_derivative(f, self.W2)\n",
    "            self.b2 -= self.learning_rate * numerical_derivative(f, self.b2)\n",
    "            \n",
    "            self.W3 -= self.learning_rate * numerical_derivative(f, self.W3)\n",
    "            self.b3 -= self.learning_rate * numerical_derivative(f, self.b3)\n",
    "\n",
    "            self.W4 -= self.learning_rate * numerical_derivative(f, self.W4)\n",
    "            self.b4 -= self.learning_rate * numerical_derivative(f, self.b4)\n",
    "            \n",
    "            if (step % 1000 == 0):\n",
    "                print(\"step = \", step, \"loss value = \", self.feed_forward_print())\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        self.xdata = input_data\n",
    "        z2 = np.dot(self.xdata, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        a3 = sigmoid(z3)\n",
    "        z4 = np.dot(a3, self.W4) + self.b4\n",
    "        y = a4 = sigmoid(z4)\n",
    "        \n",
    "        if y >= 0.5:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "            \n",
    "        return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "240ae928-4ba7-4fb6-b64b-aa2dbf60ac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss value =  4.0083964997360635\n",
      "z2 =>  [[0.96815216 0.89192463 0.32416584 0.03678995 0.05952742]\n",
      " [1.04725677 1.62282801 0.83874766 0.38453013 0.98994392]\n",
      " [1.30600681 1.69594601 1.28743978 0.86177156 0.08235938]\n",
      " [1.38511143 2.42684939 1.8020216  1.20951174 1.01277588]]\n",
      "z3 =>  [[1.68655284 3.13505012]\n",
      " [2.03234779 3.46803665]\n",
      " [1.93197808 3.60951084]\n",
      " [2.22652893 3.86245605]]\n",
      "z4 =>  [[1.44332821]\n",
      " [1.48243178]\n",
      " [1.47712345]\n",
      " [1.50352306]]\n",
      "step =  0 loss value =  3.7698825278332677\n",
      "z2 =>  [[0.95852203 0.86528113 0.29868996 0.02480646 0.03011742]\n",
      " [1.05170757 1.62900269 0.88622983 0.4209401  0.99081973]\n",
      " [1.30350799 1.70187738 1.31175673 0.88423671 0.14824105]\n",
      " [1.39669353 2.46559893 1.8992966  1.28037036 1.10894336]]\n",
      "z3 =>  [[1.55527425 3.04982677]\n",
      " [1.92679398 3.41117363]\n",
      " [1.8427319  3.5480291 ]\n",
      " [2.14701533 3.81436656]]\n",
      "z4 =>  [[-0.01676093]\n",
      " [ 0.0073141 ]\n",
      " [ 0.00369096]\n",
      " [ 0.01956092]]\n",
      "step =  1000 loss value =  2.76857672576315\n",
      "z2 =>  [[ 0.95104101  0.81655232  0.2543272   0.00953194 -0.00445727]\n",
      " [ 1.05602337  1.63930098  0.97179336  0.49035618  1.0306014 ]\n",
      " [ 1.3018174   1.71140993  1.36108453  0.93186813  0.28605997]\n",
      " [ 1.40679975  2.53415858  2.07855069  1.41269237  1.32111864]]\n",
      "z3 =>  [[1.44506817 2.97310484]\n",
      " [1.89340805 3.38862637]\n",
      " [1.83287905 3.51937647]\n",
      " [2.17305757 3.80871095]]\n",
      "z4 =>  [[-0.03439601]\n",
      " [ 0.01198451]\n",
      " [ 0.00757175]\n",
      " [ 0.03476778]]\n",
      "step =  2000 loss value =  2.763319772833954\n",
      "z2 =>  [[ 0.96258934  0.69369135  0.1173965  -0.03470713 -0.08125239]\n",
      " [ 1.04741673  1.63963413  1.12612546  0.62670253  1.1589379 ]\n",
      " [ 1.29677156  1.70826903  1.4465663   1.02493489  0.57939097]\n",
      " [ 1.38159895  2.65421181  2.45529526  1.68634455  1.81958126]]\n",
      "z3 =>  [[1.01323248 2.85680406]\n",
      " [1.67839258 3.38769233]\n",
      " [1.64307436 3.50905555]\n",
      " [2.06970213 3.8325688 ]]\n",
      "z4 =>  [[-0.10988647]\n",
      " [ 0.0314154 ]\n",
      " [ 0.02576596]\n",
      " [ 0.09030008]]\n",
      "step =  3000 loss value =  2.7369379353291063\n",
      "z2 =>  [[ 1.19395446  0.25036133 -0.63994314 -0.27021507 -0.57186054]\n",
      " [ 0.98787685  1.5540174   1.48734991  1.00623251  1.57410348]\n",
      " [ 1.34239235  1.61475427  1.65556879  1.29236824  1.33670801]\n",
      " [ 1.13631475  2.91841035  3.78286185  2.56881582  3.48267203]]\n",
      "z3 =>  [[-0.31230008  2.62985981]\n",
      " [ 2.31312299  3.5574808 ]\n",
      " [ 2.27338937  3.67313852]\n",
      " [ 3.25295467  4.00166917]]\n",
      "z4 =>  [[-1.17847829]\n",
      " [ 0.3450051 ]\n",
      " [ 0.33323553]\n",
      " [ 0.50768088]]\n",
      "step =  4000 loss value =  2.322966159971198\n",
      "z2 =>  [[ 1.35314433 -0.19644708 -1.34502369 -0.68421688 -1.20856173]\n",
      " [ 0.79864025  1.37696222  1.62217554  1.06145199  1.68314145]\n",
      " [ 1.28489753  1.44623238  1.75914987  1.31374928  1.58742941]\n",
      " [ 0.73039345  3.01964168  4.7263491   3.05941815  4.47913259]]\n",
      "z3 =>  [[-1.33769702  2.23187818]\n",
      " [ 4.60698533  3.28299139]\n",
      " [ 4.54518456  3.41810432]\n",
      " [ 6.33574227  3.66982867]]\n",
      "z4 =>  [[-3.10301103]\n",
      " [ 0.63636591]\n",
      " [ 0.627698  ]\n",
      " [ 0.66157598]]\n",
      "step =  5000 loss value =  1.9741231306858094\n",
      "z2 =>  [[ 1.32109031 -0.43653555 -1.69075268 -1.16109403 -1.39513884]\n",
      " [ 0.70024533  1.2048426   1.4249816   0.58407471  1.7291765 ]\n",
      " [ 1.29858728  1.28704728  1.58088479  0.88265227  1.66683502]\n",
      " [ 0.6777423   2.92842543  4.69661906  2.627821    4.79115036]]\n",
      "z3 =>  [[-1.78082211  0.84448812]\n",
      " [ 5.43526692  1.56669924]\n",
      " [ 5.42210562  1.6723989 ]\n",
      " [ 7.7589796   1.94794507]]\n",
      "z4 =>  [[-3.82225378]\n",
      " [ 0.70222117]\n",
      " [ 0.67315379]\n",
      " [ 0.62973942]]\n",
      "step =  6000 loss value =  1.893055789488845\n",
      "z2 =>  [[ 1.77425388 -1.0302016  -3.22077523 -3.56588874 -1.17302258]\n",
      " [ 0.1723006   0.56656418 -0.56677407 -1.14750501  2.40652326]\n",
      " [ 0.59413555  0.65608045 -0.38955972 -0.97930656  2.35231058]\n",
      " [-1.00781774  2.25284623  2.26444144  1.43907718  5.93185642]]\n",
      "z3 =>  [[-2.76484759 -4.07402435]\n",
      " [ 3.91385071 -2.18747744]\n",
      " [ 3.98816898 -2.22513351]\n",
      " [ 9.46892201  2.06981707]]\n",
      "z4 =>  [[-3.05422541]\n",
      " [ 2.75290717]\n",
      " [ 2.78518667]\n",
      " [-2.43448653]]\n",
      "step =  7000 loss value =  0.2517743987546904\n"
     ]
    }
   ],
   "source": [
    "xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "tdata = np.array([0, 1, 1, 0])\n",
    "\n",
    "xor_obj = LogicGate(\"XOR\", xdata, tdata)\n",
    "xor_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f704cab9-928f-47b7-92e3-ac1e5538b23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]  =  0\n",
      "[0 1]  =  1\n",
      "[1 0]  =  1\n",
      "[1 1]  =  0\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "for data in test_data:\n",
    "    sigmoid_val, logical_val = xor_obj.predict(data)\n",
    "    print(data, \" = \", logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f099a6f-db64-467f-bb78-97ae5e12a6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Logicgate_MLP:\n",
    "    def __init__(self, gate_name, xdata, tdata, hidden1_nodes=4, hidden2_nodes=2):\n",
    "        self.name = gate_name\n",
    "        self.xdata = xdata.reshape(4, 2)\n",
    "        self.tdata = tdata.reshape(4, 1)\n",
    "        # 은닉층1 가중치 및 편향 초기화\n",
    "        self.hidden1_nodes = hidden1_nodes\n",
    "        self.W1 = np.random.randn(2, hidden1_nodes)  # 2개의 입력, hidden1_nodes개의 은닉 노드\n",
    "        self.b1 = np.random.randn(hidden1_nodes)\n",
    "        # 은닉층2 가중치 및 편향 초기화\n",
    "        self.hidden2_nodes = hidden2_nodes\n",
    "        self.W2 = np.random.randn(hidden1_nodes, hidden2_nodes)  # hidden1_nodes개의 은닉 노드, hidden2_nodes개의 은닉 노드\n",
    "        self.b2 = np.random.randn(hidden2_nodes)\n",
    "        # 출력층 가중치 및 편향 초기화\n",
    "        self.W3 = np.random.randn(hidden2_nodes, 1)  # hidden2_nodes 개의 은닉 노드, 1개의 출력 노드\n",
    "        self.b3 = np.random.randn(1)\n",
    "        self.learning_rate = 1e-2\n",
    "    def feed_forward(self, xdata):\n",
    "        z1 = np.dot(xdata, self.W1) + self.b1\n",
    "        a1 = sigmoid(z1)\n",
    "        z2 = np.dot(a1, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        y = sigmoid(z3)\n",
    "        return y\n",
    "    def loss_func(self, y):\n",
    "        delta = 1e-7\n",
    "        return -np.sum(self.tdata*np.log(y+delta)+(1-self.tdata)*np.log((1-y)+delta))\n",
    "        \n",
    "        return -np.sum(self.tdata * np.log(y + delta) + (1 - self.tdata) * np.log((1 - y) + delta))\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        f = lambda x: self.loss_func(self.feed_forward(self.xdata))\n",
    "        print(\"Initial loss value = \", self.loss_func(self.feed_forward(self.xdata)))\n",
    "        for step in range(20001):\n",
    "            self.W1 -= self.learning_rate * numerical_derivative(f, self.W1)\n",
    "            self.b1 -= self.learning_rate * numerical_derivative(f, self.b1)\n",
    "            self.W2 -= self.learning_rate * numerical_derivative(f, self.W2)\n",
    "            self.b2 -= self.learning_rate * numerical_derivative(f, self.b2)\n",
    "            self.W3 -= self.learning_rate * numerical_derivative(f, self.W3)\n",
    "            self.b3 -= self.learning_rate * numerical_derivative(f, self.b3)\n",
    "            if (step % 1000 == 0):\n",
    "                print(\"step = \", step, \"loss value = \", self.loss_func(self.feed_forward(self.xdata)))\n",
    "    def predict(self, input_data):\n",
    "        y = self.feed_forward(input_data)\n",
    "        if y > 0.5:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "        return y, result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42996d95-094e-4524-89aa-cf64cfda420c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss value =  5.053716796952118\n",
      "step =  0 loss value =  4.99297731114802\n",
      "step =  1000 loss value =  2.721798912772436\n",
      "step =  2000 loss value =  2.66051109305728\n",
      "step =  3000 loss value =  2.527430485395282\n",
      "step =  4000 loss value =  2.3153709119804136\n",
      "step =  5000 loss value =  2.1170790445794117\n",
      "step =  6000 loss value =  1.9373063636629306\n",
      "step =  7000 loss value =  1.3635504769118052\n",
      "step =  8000 loss value =  0.596286200193133\n",
      "step =  9000 loss value =  0.27757107874614617\n",
      "step =  10000 loss value =  0.16068346363516905\n",
      "step =  11000 loss value =  0.10771168127553363\n",
      "step =  12000 loss value =  0.07914842441320935\n",
      "step =  13000 loss value =  0.061771729090964775\n",
      "step =  14000 loss value =  0.050266641220513546\n",
      "step =  15000 loss value =  0.042165423226165434\n",
      "step =  16000 loss value =  0.036190203099653706\n",
      "step =  17000 loss value =  0.03162143367071645\n",
      "step =  18000 loss value =  0.02802640400516964\n",
      "step =  19000 loss value =  0.025130792823701675\n",
      "step =  20000 loss value =  0.02275301763115407\n",
      "[0 0]  =  0\n",
      "[0 1]  =  1\n",
      "[1 0]  =  1\n",
      "[1 1]  =  0\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터\n",
    "xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "tdata = np.array([0, 1, 1, 0]) # XOR 데이터\n",
    "# 모델 생성\n",
    "XOR_obj = Logicgate_MLP(\"XOR\", xdata, tdata, hidden1_nodes=4, hidden2_nodes=2)\n",
    "XOR_obj.train()\n",
    "# 테스트 데이터\n",
    "test_xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "for input_data in test_xdata:\n",
    "    (sigmoid_val, logical_val) = XOR_obj.predict(input_data.reshape(1, 2))\n",
    "    print(input_data, \" = \", logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdc009ab-ab40-465b-bc77-9835865f312b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02918861, 0.11138822, 0.81342188, 0.66411931],\n",
       "       [0.32125958, 0.17594783, 0.10001365, 0.41449162]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde0fd0-2b36-4ad6-81bc-606b887ae508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
