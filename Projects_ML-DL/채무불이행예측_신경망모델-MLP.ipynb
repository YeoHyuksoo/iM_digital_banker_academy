{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "238307e5-c48d-4261-980f-885c88c681bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # 윈도우의 한글 폰트\n",
    "plt.rcParams['axes.unicode_minus'] = False       # 마이너스 기호 깨짐 방지\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c3204fe-2885-48c1-ab5b-99562b65cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 처리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv(\"/data/train.csv\")\n",
    "test_df = pd.read_csv(\"/data/test.csv\")\n",
    "\n",
    "# 새로운 조합 변수 추가\n",
    "for df in [train_df, test_df]:\n",
    "    df['신용한도_대비_미상환율'] = df['현재 미상환 신용액'] / (df['최대 신용한도'] + 1)\n",
    "    df['연체_빈도율'] = df['신용 문제 발생 횟수'] / (df['신용 거래 연수'] + 1)\n",
    "    df['소득_대비_월_부채'] = df['월 상환 부채액'] / (df['연간 소득'] / 12 + 1)\n",
    "    df['부채비율'] = df['현재 대출 잔액'] / (df['연간 소득'] + 1)\n",
    "    df['개인파산_영향력'] = df['개인 파산 횟수'] * df['신용 문제 발생 횟수']\n",
    "\n",
    "\n",
    "# \"UID\" 컬럼 유지 (제출 파일용)\n",
    "test_uid = test_df[\"UID\"]\n",
    "\n",
    "# \"UID\" 컬럼 삭제\n",
    "train_df.drop(columns=[\"UID\"], inplace=True)\n",
    "test_df.drop(columns=[\"UID\"], inplace=True)\n",
    "\n",
    "# X, y 분리\n",
    "X = train_df.drop(columns=[\"채무 불이행 여부\"])\n",
    "y = train_df[\"채무 불이행 여부\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0154b5a-9277-411f-b25a-b76ba983ec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_years(val):\n",
    "#     if val == '1년 미만':\n",
    "#         return 0\n",
    "#     elif val == '10년 이상':\n",
    "#         return 10\n",
    "#     else:\n",
    "#         # '4년', '6년' 등에서 '년'을 제거하고 정수형으로 변환\n",
    "#         return int(val.replace('년', ''))\n",
    "\n",
    "# # train, test 데이터에 대해 변환 적용\n",
    "# X['현재 직장 근속 연수'] = X['현재 직장 근속 연수'].apply(convert_years)\n",
    "# test_df['현재 직장 근속 연수'] = test_df['현재 직장 근속 연수'].apply(convert_years)\n",
    "\n",
    "# # 변환 결과 확인\n",
    "# print(X['현재 직장 근속 연수'].unique())\n",
    "\n",
    "\n",
    "# 현재 직장 근속 연수를 이진 변수로 변환 (1년 미만: 1, 1년 이상: 0)\n",
    "X['근속연수_1년미만'] = (X['현재 직장 근속 연수'] == '1년 미만').astype(int)\n",
    "test_df['근속연수_1년미만'] = (test_df['현재 직장 근속 연수'] == '1년 미만').astype(int)\n",
    "\n",
    "# 기존 변수 제거\n",
    "X.drop(columns=['현재 직장 근속 연수'], inplace=True)\n",
    "test_df.drop(columns=['현재 직장 근속 연수'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c19f7533-ed73-4528-a368-7d31296e11ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩 적용\n",
    "X = pd.get_dummies(X, columns=[\"주거 형태\", \"대출 목적\", \"대출 상환 기간\"], drop_first=True)\n",
    "test_df = pd.get_dummies(test_df, columns=[\"주거 형태\", \"대출 목적\", \"대출 상환 기간\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc79d31c-4102-4cbb-bcd8-f588f27c8d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# # 타깃 인코딩을 적용할 범주형 변수 목록\n",
    "# target_encoding_cols = ['주거 형태', '대출 목적', '대출 상환 기간']\n",
    "\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=31)\n",
    "\n",
    "# for col in target_encoding_cols:\n",
    "#     target_mean_map = {}\n",
    "\n",
    "#     for train_idx, val_idx in kf.split(X):\n",
    "#         train_fold, val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#         y_train_fold = y.iloc[train_idx]  # 🔹 y도 동일한 인덱싱으로 분할\n",
    "\n",
    "#         # 🔹 타깃 평균 계산 (X_train과 y를 합쳐서 groupby)\n",
    "#         train_fold = train_fold.copy()\n",
    "#         train_fold['y'] = y_train_fold  # 🔥 여기서 y 값을 추가!\n",
    "\n",
    "#         mean_encoding = train_fold.groupby(col)['y'].mean().to_dict()\n",
    "#         target_mean_map.update(mean_encoding)\n",
    "\n",
    "#     # 새로운 타깃 인코딩 컬럼 추가\n",
    "#     X[col + '_타깃인코딩'] = X[col].map(target_mean_map)\n",
    "#     test_df[col + '_타깃인코딩'] = test_df[col].map(target_mean_map)\n",
    "\n",
    "# # 원본 범주형 컬럼 삭제\n",
    "# X.drop(columns=target_encoding_cols, inplace=True)\n",
    "# test_df.drop(columns=target_encoding_cols, inplace=True)\n",
    "\n",
    "# print(\"✅ 타깃 인코딩 적용 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f02c509e-e9a8-4687-87d4-56c79971c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 중요도가 낮은 \"대출 목적\" 컬럼들 제거\n",
    "# drop_loan_purpose_cols = [\n",
    "#     '대출 목적_사업 대출', '대출 목적_여행 자금', \n",
    "#     '대출 목적_주택 개보수', '대출 목적_주택 구매'\n",
    "# ]\n",
    "\n",
    "# # 변수 삭제\n",
    "# X.drop(columns=drop_loan_purpose_cols, inplace=True)\n",
    "# test_df.drop(columns=drop_loan_purpose_cols, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03d3b58f-3873-4e68-a69c-14e531586a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그 변환\n",
    "log_columns = [\"현재 미상환 신용액\", \"월 상환 부채액\", \"현재 대출 잔액\", \"연간 소득\",\n",
    "               '신용한도_대비_미상환율', '소득_대비_월_부채', '부채비율'] # 최대 신용한도 컬럼도 추가 가능\n",
    "for col in log_columns:\n",
    "    X[col] = np.log1p(X[col])\n",
    "    test_df[col] = np.log1p(test_df[col])\n",
    "\n",
    "# \"마지막 연체 이후 경과 개월 수\"가 0이면 \"연체 없음\" 컬럼 추가\n",
    "# X[\"연체 없음\"] = (X[\"마지막 연체 이후 경과 개월 수\"] == 0).astype(int)\n",
    "# test_df[\"연체 없음\"] = (test_df[\"마지막 연체 이후 경과 개월 수\"] == 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a3e5160-25e9-423d-b958-4bd99239846e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 35)\n",
      "(2062, 35)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "test_imputed = imputer.transform(test_df)\n",
    "print(X_imputed.shape)\n",
    "print(test_imputed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a0abac1-5819-48e9-a444-0f0606d8552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X_imputed)\n",
    "# test_scaled = scaler.transform(test_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a413b19-5a16-4017-8407-08c1aeae04ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_resampled, y_resampled = smote.fit_resample(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77820b2-434b-4ce1-9bd6-529f93ee2653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "\n",
    "classes = np.unique(y)\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y)\n",
    "class_weight_dict = dict(zip(classes, class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8c7ab22-53a7-4a42-821d-29540cbf6eb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[0;32m     34\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, error_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_imputed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest ROC AUC:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32m~\\PycharmProjects\\NLP\\.venv\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\PycharmProjects\\NLP\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\PycharmProjects\\NLP\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\NLP\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32m~\\PycharmProjects\\NLP\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\NLP\\.venv\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\PycharmProjects\\NLP\\.venv\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\PycharmProjects\\NLP\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\PycharmProjects\\NLP\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\PycharmProjects\\NLP\\.venv\\lib\\site-packages\\scikeras\\wrappers.py:1491\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m   1489\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight\n\u001b[0;32m   1490\u001b[0m     sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m-> 1491\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\PycharmProjects\\NLP\\.venv\\lib\\site-packages\\scikeras\\wrappers.py:760\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    755\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit__epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[0;32m    757\u001b[0m )\n\u001b[0;32m    758\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 760\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    761\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    762\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    763\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    764\u001b[0m     warm_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start,\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    766\u001b[0m )\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\PycharmProjects\\NLP\\.venv\\lib\\site-packages\\scikeras\\wrappers.py:926\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_encoder_\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[0;32m    924\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_encoder_\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m--> 926\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_model_compatibility\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_keras_model(\n\u001b[0;32m    929\u001b[0m     X,\n\u001b[0;32m    930\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    936\u001b[0m )\n",
      "File \u001b[1;32m~\\PycharmProjects\\NLP\\.venv\\lib\\site-packages\\scikeras\\wrappers.py:549\u001b[0m, in \u001b[0;36mBaseWrapper._check_model_compatibility\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;66;03m# check if this is a multi-output model\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_outputs_expected_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    546\u001b[0m     \u001b[38;5;66;03m# n_outputs_expected_ is generated by data transformers\u001b[39;00m\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;66;03m# we recognize the attribute but do not force it to be\u001b[39;00m\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;66;03m# generated\u001b[39;00m\n\u001b[1;32m--> 549\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_expected_ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    550\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    551\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected a Keras model input of size\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    552\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_expected_\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    553\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39moutputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    554\u001b[0m         )\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# check that if the user gave us a loss function it ended up in\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;66;03m# the actual model\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "# 모델 생성 함수 수정\n",
    "def create_model(dropout_rate=0.2, l2_reg=0.01):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(l2_reg)),\n",
    "        keras.layers.Dropout(dropout_rate),\n",
    "        keras.layers.Dense(32, activation='relu', kernel_regularizer=keras.regularizers.l2(l2_reg)),\n",
    "        keras.layers.Dropout(dropout_rate),\n",
    "        keras.layers.Dense(1, activation='sigmoid')  # 이진 분류\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(name=\"auc\")])  # AUC 이름 고정\n",
    "    return model\n",
    "\n",
    "# 하이퍼파라미터 후보군\n",
    "dropout_rates = [0.2, 0.3, 0.4]\n",
    "l2_regs = [0.001, 0.01, 0.1]\n",
    "\n",
    "# StratifiedKFold 설정 (5폴드)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_auc = 0\n",
    "best_params = None\n",
    "\n",
    "# 하이퍼파라미터 조합별로 KFold 검증\n",
    "for dropout in dropout_rates:\n",
    "    for l2 in l2_regs:\n",
    "        print(f\"\\n🔍 [교차 검증 시작] dropout: {dropout}, l2_reg: {l2}\")\n",
    "\n",
    "        fold_aucs = []  # 각 Fold의 AUC 저장\n",
    "        for train_idx, val_idx in cv.split(X_scaled, y):\n",
    "            X_train, X_val = X_imputed[train_idx], X_imputed[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "            model = create_model(dropout, l2)\n",
    "\n",
    "            # 조기 종료 설정 (이제 \"val_auc\"가 정확하게 고정됨)\n",
    "            early_stopping = keras.callbacks.EarlyStopping(monitor='val_auc', patience=5, restore_best_weights=True)\n",
    "\n",
    "            # 모델 학습\n",
    "            history = model.fit(\n",
    "                X_scaled, y,\n",
    "                epochs=30,\n",
    "                batch_size=32,\n",
    "                validation_split=0.2,\n",
    "                class_weight=class_weight_dict,  # 클래스 가중치 적용!\n",
    "                callbacks=[early_stopping]\n",
    "            )\n",
    "\n",
    "\n",
    "            # 검증 데이터 AUC 평가\n",
    "            val_auc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "            fold_aucs.append(val_auc)\n",
    "\n",
    "        # 평균 AUC 계산\n",
    "        mean_auc = np.mean(fold_aucs)\n",
    "        print(f\"✅ [교차 검증 완료] dropout: {dropout}, l2: {l2}, 평균 AUC: {mean_auc}\")\n",
    "\n",
    "        # 최고 AUC 갱신\n",
    "        if mean_auc > best_auc:\n",
    "            best_auc = mean_auc\n",
    "            best_params = (dropout, l2)\n",
    "\n",
    "print(f\"\\n🎯 최고 AUC: {best_auc} (dropout: {best_params[0]}, l2: {best_params[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db953ed9-fc8a-484b-aebb-97bee5124174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 하이퍼파라미터 그리드 설정\n",
    "# param_grid = {\n",
    "#     'units': [64, 128],\n",
    "#     'dropout': [0.2, 0.5],\n",
    "#     'l2_reg': [0.0001, 0.001],\n",
    "#     'learning_rate': [0.001, 0.01],\n",
    "#     'batch_size': [32, 64],\n",
    "#     'epochs': [50]  # 조기 종료가 있으므로 크게 설정\n",
    "# }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
