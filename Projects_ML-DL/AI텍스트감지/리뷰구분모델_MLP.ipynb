{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f2eee3-e15a-4f96-9526-5c27a66500af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,064</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │         \u001b[38;5;34m320,064\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m1,040\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">963,365</span> (3.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m963,365\u001b[0m (3.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321,121</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m321,121\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">642,244</span> (2.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m642,244\u001b[0m (2.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "965f9b37-c65b-4bf7-98cb-b564aa954da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\PycharmProjects\\iM_ML-DL\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 75ms/step - accuracy: 0.7213 - loss: 0.5600 - val_accuracy: 0.9047 - val_loss: 0.2345\n",
      "Epoch 2/5\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.9108 - loss: 0.2447 - val_accuracy: 0.9106 - val_loss: 0.2155\n",
      "Epoch 3/5\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 62ms/step - accuracy: 0.9268 - loss: 0.2049 - val_accuracy: 0.9082 - val_loss: 0.2180\n",
      "Epoch 4/5\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9392 - loss: 0.1760 - val_accuracy: 0.9064 - val_loss: 0.2245\n",
      "Epoch 5/5\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.9489 - loss: 0.1505 - val_accuracy: 0.9076 - val_loss: 0.2266\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "Accuracy: 90.76%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.90      0.91      0.91      4016\n",
      "          OR       0.91      0.90      0.91      4071\n",
      "\n",
      "    accuracy                           0.91      8087\n",
      "   macro avg       0.91      0.91      0.91      8087\n",
      "weighted avg       0.91      0.91      0.91      8087\n",
      "\n",
      "\n",
      "Total Training Time: 92.75 seconds\n"
     ]
    }
   ],
   "source": [
    "import time  # 시간 측정을 위한 모듈\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 데이터 불러오기\n",
    "data = pd.read_csv('fake_reviews_dataset.csv')  # 데이터 파일 경로 수정 필요\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "data['label_encoded'] = label_encoder.fit_transform(data['label'])\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # 최대 5000개의 단어 사용\n",
    "X = tfidf.fit_transform(data['text_']).toarray()  # 텍스트 데이터를 TF-IDF 벡터로 변환\n",
    "y = data['label_encoded']\n",
    "\n",
    "# 데이터 분할 (훈련 세트, 테스트 세트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape[1])\n",
    "# MLP 모델 구축\n",
    "# model = Sequential()\n",
    "# model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))  # 첫 번째 은닉층\n",
    "# model.add(Dense(32, activation='relu'))  # 두 번째 은닉층\n",
    "# model.add(Dense(1, activation='sigmoid'))  # 출력층 (이진 분류)\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.5))  # 첫 번째 Dropout\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))  # 두 번째 Dropout\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습 시간 측정\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=128, validation_data=(X_test, y_test))\n",
    "end_time = time.time()\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# 정확도 출력\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# 성능 보고서 출력\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# 학습 시간 출력\n",
    "print(f\"\\nTotal Training Time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5640a26e-fccf-43b6-9417-aed2631c6ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=64, optimizer=adam; total time=   7.1s\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=128, optimizer=adam; total time=   1.6s\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=128, optimizer=adam; total time=   1.5s\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=128, optimizer=adam; total time=   1.5s\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=128, optimizer=sgd; total time=   2.0s\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=128, optimizer=sgd; total time=   1.6s\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=128, optimizer=sgd; total time=   1.6s\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=256, optimizer=adam; total time=   2.1s\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=256, optimizer=adam; total time=   1.5s\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=256, optimizer=adam; total time=   2.1s\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=256, optimizer=sgd; total time=   1.6s\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=256, optimizer=sgd; total time=   1.7s\n",
      "[CV] END batch_size=32, epochs=5, hidden_units=256, optimizer=sgd; total time=   1.9s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=128, optimizer=adam; total time=   1.6s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=128, optimizer=adam; total time=   1.6s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=128, optimizer=adam; total time=   1.7s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=128, optimizer=sgd; total time=   1.6s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=128, optimizer=sgd; total time=   1.7s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=128, optimizer=sgd; total time=   1.8s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=256, optimizer=adam; total time=   1.6s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=256, optimizer=adam; total time=   1.7s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=256, optimizer=adam; total time=   1.6s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=256, optimizer=sgd; total time=   1.8s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=256, optimizer=sgd; total time=   1.6s\n",
      "[CV] END batch_size=32, epochs=10, hidden_units=256, optimizer=sgd; total time=   2.0s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=128, optimizer=adam; total time=   1.9s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=128, optimizer=adam; total time=   1.8s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=128, optimizer=adam; total time=   1.6s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=128, optimizer=sgd; total time=   1.8s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=128, optimizer=sgd; total time=   1.7s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=128, optimizer=sgd; total time=   1.5s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=256, optimizer=adam; total time=   1.7s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=256, optimizer=adam; total time=   1.7s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=256, optimizer=adam; total time=   1.7s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=256, optimizer=sgd; total time=   1.7s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=256, optimizer=sgd; total time=   1.9s\n",
      "[CV] END batch_size=64, epochs=5, hidden_units=256, optimizer=sgd; total time=   1.8s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=128, optimizer=adam; total time=   1.7s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=128, optimizer=adam; total time=   1.9s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=128, optimizer=adam; total time=   1.6s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=128, optimizer=sgd; total time=   1.6s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=128, optimizer=sgd; total time=   1.8s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=128, optimizer=sgd; total time=   1.8s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=256, optimizer=adam; total time=   1.7s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=256, optimizer=adam; total time=   1.8s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=256, optimizer=adam; total time=   1.8s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=256, optimizer=sgd; total time=   1.6s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=256, optimizer=sgd; total time=   2.3s\n",
      "[CV] END batch_size=64, epochs=10, hidden_units=256, optimizer=sgd; total time=   1.3s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 72 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n72 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\82102\\PycharmProjects\\iM_ML-DL\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\82102\\PycharmProjects\\iM_ML-DL\\.venv\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\82102\\PycharmProjects\\iM_ML-DL\\.venv\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\82102\\PycharmProjects\\iM_ML-DL\\.venv\\lib\\site-packages\\scikeras\\wrappers.py\", line 928, in _fit\n    self._ensure_compiled_model()\n  File \"C:\\Users\\82102\\PycharmProjects\\iM_ML-DL\\.venv\\lib\\site-packages\\scikeras\\wrappers.py\", line 439, in _ensure_compiled_model\n    if not self.model_.compiled:\nAttributeError: 'Sequential' object has no attribute 'compiled'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# GridSearchCV로 하이퍼파라미터 튜닝\u001b[39;00m\n\u001b[0;32m     46\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# 최적의 파라미터 출력\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_result\u001b[38;5;241m.\u001b[39mbest_score_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_result\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\PycharmProjects\\iM_ML-DL\\.venv\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\PycharmProjects\\iM_ML-DL\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\PycharmProjects\\iM_ML-DL\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\iM_ML-DL\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:996\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    994\u001b[0m     )\n\u001b[1;32m--> 996\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\PycharmProjects\\iM_ML-DL\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 72 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n72 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\82102\\PycharmProjects\\iM_ML-DL\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\82102\\PycharmProjects\\iM_ML-DL\\.venv\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\82102\\PycharmProjects\\iM_ML-DL\\.venv\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\82102\\PycharmProjects\\iM_ML-DL\\.venv\\lib\\site-packages\\scikeras\\wrappers.py\", line 928, in _fit\n    self._ensure_compiled_model()\n  File \"C:\\Users\\82102\\PycharmProjects\\iM_ML-DL\\.venv\\lib\\site-packages\\scikeras\\wrappers.py\", line 439, in _ensure_compiled_model\n    if not self.model_.compiled:\nAttributeError: 'Sequential' object has no attribute 'compiled'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scikeras.wrappers import KerasClassifier  # scikeras 사용\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 데이터 불러오기\n",
    "data = pd.read_csv('fake_reviews_dataset.csv')\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "data['label_encoded'] = label_encoder.fit_transform(data['label'])\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(data['text_']).toarray()\n",
    "y = data['label_encoded']\n",
    "\n",
    "# 데이터 분할 (훈련 세트, 테스트 세트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# MLP 모델 함수 정의\n",
    "def create_model(activation='relu', optimizer='adam', hidden_units=128):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, input_dim=X_train.shape[1], activation=activation))  # 첫 번째 은닉층\n",
    "    model.add(Dense(hidden_units // 2, activation=activation))  # 두 번째 은닉층\n",
    "    model.add(Dense(1, activation='sigmoid'))  # 출력층\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])  # 모델 컴파일\n",
    "    return model\n",
    "\n",
    "# KerasClassifier 생성 시 'build_fn' 대신 'model' 파라미터 사용\n",
    "model = KerasClassifier(model=create_model, activation='relu', optimizer='adam', hidden_units=128, verbose=0)\n",
    "\n",
    "# 하이퍼파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'hidden_units': [64, 128, 256],  # 은닉층 뉴런 수\n",
    "    'optimizer': ['adam', 'sgd'],    # 최적화 알고리즘\n",
    "    'batch_size': [32, 64],          # 배치 크기\n",
    "    'epochs': [5, 10]                # 에포크 수\n",
    "}\n",
    "\n",
    "# GridSearchCV로 하이퍼파라미터 튜닝\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=2)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터 출력\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "\n",
    "# 최적의 모델로 평가\n",
    "best_model = grid_result.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Optimized Model Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d61645-5623-461b-a5d1-910457b32dce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c40a89ad-4725-4295-867f-9d2819cfa0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\PycharmProjects\\iM_ML-DL\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1011/1011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8296 - loss: 0.3836 - val_accuracy: 0.8912 - val_loss: 0.2645\n",
      "Epoch 2/5\n",
      "\u001b[1m1011/1011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.8962 - loss: 0.2546 - val_accuracy: 0.8992 - val_loss: 0.2486\n",
      "Epoch 3/5\n",
      "\u001b[1m1011/1011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9037 - loss: 0.2351 - val_accuracy: 0.8998 - val_loss: 0.2427\n",
      "Epoch 4/5\n",
      "\u001b[1m1011/1011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9111 - loss: 0.2185 - val_accuracy: 0.9065 - val_loss: 0.2275\n",
      "Epoch 5/5\n",
      "\u001b[1m1011/1011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9174 - loss: 0.2041 - val_accuracy: 0.9027 - val_loss: 0.2354\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Accuracy: 90.27%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 데이터 불러오기\n",
    "data = pd.read_csv('fake_reviews_dataset.csv')  # 데이터 파일 경로를 수정해주세요\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "data['label_encoded'] = label_encoder.fit_transform(data['label'])\n",
    "\n",
    "# Word2Vec 모델 훈련 (단어 벡터화)\n",
    "tokenized_reviews = [review.split() for review in data['text_']]  # 리뷰 텍스트를 단어 단위로 분할\n",
    "word2vec_model = Word2Vec(tokenized_reviews, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# 리뷰 텍스트를 벡터화 (단어 벡터 평균)\n",
    "def vectorize_text(text):\n",
    "    words = text.split()\n",
    "    word_vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "X = np.array([vectorize_text(review) for review in data['text_']])\n",
    "y = data['label_encoded']\n",
    "\n",
    "# 데이터 분할 (훈련 세트, 테스트 세트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# MLP 모델 구축\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))  # 첫 번째 은닉층\n",
    "model.add(Dense(64, activation='relu'))  # 두 번째 은닉층\n",
    "model.add(Dense(1, activation='sigmoid'))  # 출력층 (이진 분류)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# 정확도 출력\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96991ead-dbd1-4741-a554-41b26da3e969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp39-cp39-win_amd64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\82102\\pycharmprojects\\im_ml-dl\\.venv\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\82102\\pycharmprojects\\im_ml-dl\\.venv\\lib\\site-packages (from gensim) (1.11.4)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\82102\\pycharmprojects\\im_ml-dl\\.venv\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n",
      "Downloading gensim-4.3.3-cp39-cp39-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.4/24.0 MB 16.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.6/24.0 MB 16.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.0/24.0 MB 17.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.7/24.0 MB 24.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 23.0 MB/s eta 0:00:00\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.3 smart-open-7.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2067d194-191f-4ba3-a16d-d2eb2d93fd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
